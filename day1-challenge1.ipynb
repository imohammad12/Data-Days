{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "from io import StringIO\n",
    "from scipy import spatial\n",
    "from sklearn.feature_selection import chi2\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM,Dense,Input,Bidirectional, CuDNNLSTM , Dropout\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "from scipy import spatial\n",
    "from random import shuffle\n",
    "import pickle as pk\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import gc\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"/Users/mohammad/Documents/Internship-IAI/Data-days-stuff/divar_posts_dataset.csv\"\n",
    "data = pd.read_csv(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(947635,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_desc_title = data['desc'] + ' ' + data['title']\n",
    "data_desc_title.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_desc_title = data_desc_title.str.replace('.', ' ')\n",
    "data_desc_title = data_desc_title.str.replace('?', ' ')\n",
    "data_desc_title = data_desc_title.str.replace('!', ' ')\n",
    "data_desc_title = data_desc_title.str.replace('،', ' ')\n",
    "data_desc_title = data_desc_title.str.replace('\\n', ' ')\n",
    "data_desc_title = data_desc_title.str.replace(',', ' ')\n",
    "data_desc_title = data_desc_title.str.replace('؟', ' ')\n",
    "data_desc_title = data_desc_title.str.replace('!', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = data_desc_title.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.basicConfig(format=’%(asctime)s : %(levelname)s : %(message)s’, level=logging.INFO)\n",
    "model2 = gensim.models.Word2Vec(\n",
    "    documents,\n",
    "    size=60,\n",
    "    window=10,\n",
    "    min_count=7,\n",
    "    workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147048031, 178045330)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.train(documents, total_examples=len(documents), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.build_vocab(['زندگی'], update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.add(['<UNK>'], [(np.ones(60))],replace = True)\n",
    "model2.wv.add(['<PAD>'], [(np.zeros(60))],replace = True)\n",
    "model2.wv['<UNK>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('divar_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = gensim.models.Word2Vec.load('divar_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = data['desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = descs.str.replace('.', ' . ')\n",
    "descs = descs.str.replace('?', ' ؟ ')\n",
    "descs = descs.str.replace('!', ' ! ')\n",
    "descs = descs.str.replace('،', ' ، ')\n",
    "# descs = descs.str.replace('\\n', ' . ')\n",
    "descs = descs.str.replace(',', ' ، ')\n",
    "descs = descs.str.replace('؟ ', ' ؟ ')\n",
    "# descs = descs.str.replace('...', ' ... ')\n",
    "descs = descs.str.replace(':', ' : ')\n",
    "descs = descs.str.replace('_', ' _ ')\n",
    "descs = descs.str.replace('-', ' - ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = descs.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "puncs = ['!', '.', '?', ')', '(', '،', '؟', ',', ';', '-', '_', '«', ':', '...', '»', '/']\n",
    "X_train = []\n",
    "Y_train = []\n",
    "window = 10\n",
    "pads = window *['<PAD>']\n",
    "for sent in descs[:500000]:\n",
    "    intersect = set(sent).intersection(set(puncs))\n",
    "    if len(intersect) == 0:\n",
    "        continue;\n",
    "    sent2 = pads + sent + pads\n",
    "    for w in sent:\n",
    "        ytmp = (len(puncs) + 1) * [0]\n",
    "        if w in intersect:\n",
    "            ytmp[puncs.index(w)] = 1\n",
    "        else:\n",
    "            ytmp[len(puncs)] = 1\n",
    "        xtmp = sent2[sent2.index(w) - window:sent2.index(w)]\n",
    "        X_train.append(xtmp)\n",
    "        Y_train.append(ytmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ = 10\n",
    "def wordToVec(data):\n",
    "    for s in range(len(data)):\n",
    "        n = MAX_SEQ - len(data[s])\n",
    "        if n < 0:\n",
    "            data[s] = data[s][:MAX_SEQ]\n",
    "        else:\n",
    "            for i in range(n):\n",
    "                data[s].append('<PAD>')\n",
    "        for v in range(len(data[s])):\n",
    "            if data[s][v] not in model2.wv:\n",
    "                data[s][v] = model2.wv['<UNK>']\n",
    "            else:\n",
    "                data[s][v] = model2.wv[data[s][v]]\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation = X_train[450000:500000].copy()\n",
    "Y_validation = Y_train[450000:500000].copy()\n",
    "X_train = X_train[0:200000].copy()\n",
    "Y_train = Y_train[0:200000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = wordToVec(X_train)\n",
    "X_validation = wordToVec(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(Y_train)\n",
    "Y_validation = np.array(Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 10, 60)            0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 10, 100)           64400     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 17)                867       \n",
      "=================================================================\n",
      "Total params: 150,717\n",
      "Trainable params: 150,717\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 512\n",
    "input_layer = Input(batch_shape = (None, MAX_SEQ, 60))\n",
    "lstm_layer1 = LSTM(units=100, return_sequences=True)(input_layer)\n",
    "lstm_layer2 = LSTM(units=100, dropout=0.25)(lstm_layer1)\n",
    "\n",
    "lstm_out1 = Dense(50, activation=\"relu\" )(lstm_layer2)\n",
    "\n",
    "output_layer = Dense(17, activation=\"softmax\")(lstm_out1)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam' , metrics=['accuracy'] )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200000 samples, validate on 50000 samples\n",
      "Epoch 1/1\n",
      "200000/200000 [==============================] - 63s 317us/step - loss: 0.3483 - acc: 0.8868 - val_loss: 0.4486 - val_acc: 0.8651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13c7d0710>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCH_SIZE = 1\n",
    "model.fit(X_train, Y_train,validation_data=(X_validation,Y_validation), epochs=EPOCH_SIZE, batch_size=BATCH_SIZE  , verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
